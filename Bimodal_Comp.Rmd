---
title: "Bimodal Distribution"
output: html_notebook
---

In this notebook, we try to fit a bimodal distribution, first with a uniform distribution, using two methods - one that should be robust against local minima and one that isn't. Next, we will fit the data with a polynomial that should capture the bimodality.

```{r}
library(ggplot2)
```



```{r}
# Generate the data (the data could be saccades and express saccades, for example)
lat_sac <- 150  # mean latency for a saccade
lat_exp <- 80  # mean latency for an express saccade

width   <- 5   # width of the gaussian

# generate data with 1500 data points for normal saccades and 500 data points for express saccades
lat<-c(rnorm(1500,lat_sac,width),rnorm(500,lat_exp,width))

hist(lat, breaks = 40)
```


```{r}
# Step One: try fit a unimodal distribution using simplex

n <- length(lat)

# current data and preditions are being plotted
getregpred <- function(params,data){
  # here, we calculate the data from our independent variable under the assumption of the parameters assuming values b0(mean) and b1(width). Note that the names are hard coded here and that this function will only work for a linear regression. This is similar to the function that generated the data, but without the error term.
  getregpred <- rnorm(n,params["b0"],params["b1"])
  
  #plt1 <- hist(data,breaks = 20, plot = FALSE)
  #plt2 <- hist(getregpred, breaks = 40, plot= FALSE)
  #plot(plt1,col=rgb(0,0,1,1/4), xlim=c(0,200))
  #plot(plt2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
  # return the computed regression data so we can calculate the deviation to the measured data
  return(getregpred)
}

# Get the computed predictions and compute how much they deviate

rmsd <- function(params,data1){
  # generate predictions
  preds <- getregpred(params,data1)
  #evaluate the deviation, this computes the sum of squared deviations between data points and devides by the total number of data points to get the mean summed square deviation
  # first: sort data and predicitons
  sorted_preds<- sort(preds)
  sorted_data <- sort(data1)
  
  rmsd <- sqrt(sum((sorted_preds-sorted_data)^2)/length(sorted_preds))
}


# randomly define start parameters
pick_params <- function(param1,param2){
  b0  <- sample(param1,1)
  b1  <- sample(param2,1)
  
  startParams <- c(b0,b1)
  names(startParams) <- c("b0","b1")
  
  return(startParams)
}

```

```{r}
#plot the error surface when the distribution above is fitted with a unimodal model
#x-axis: mean
#y-axis: width 
#color: sum squared deviance

means <- seq(0,200,10)
widths<- seq(0,200,10)

error_table <- matrix(0,nrow=length(means)*length(widths),ncol=3)
colnames(error_table) <- c("mean","width","error")

rcount <- 0

for (m in means){
  for (w in widths){
    rcount <- rcount+1
    params <- c(m,w)
    names(params) <- c("b0","b1")
    error <- rmsd(params,lat)
    
    error_table[rcount,1]  <- m
    error_table[rcount,2] <- w
    error_table[rcount,3] <- error
  }
}

error_table<-as.data.frame(error_table)

error_surface <- ggplot(data = error_table, aes(mean, width)) + geom_tile(aes(fill = error), colour = "white") + scale_fill_gradient(low = "white",high = "steelblue")

error_surface

```
Only a local minimum is observed, the model should catch that easily. The minimum of errors is located at ~135 ms mean latency and a narrow width (0).


```{r}
# Start the optimalization process with boundaries (L-BFGS-B):
# boundaries are used because the mean latency and the width cannot go negative
# the estimation is repeated "reps" times for a more robust measure (start parameters are fixed)

reps <- 1000
param_tableSMPL <- matrix(0,reps,2) 

# define a range of start parameters, the function randomly picks one combination before each estimation

param_means  <- seq(0,250,10)
param_width  <- seq(0,100,10)

for(r in 1:reps){
  #choose start parameters
  startParams <- pick_params(param_means,param_width)
  #estimate parameters
  xoutSMPL   <- optim(startParams,rmsd,data1=lat,method = "L-BFGS-B", lower = rep(1, length(startParams)), upper = c(300,200))
  #write to table
  param_tableSMPL[r,1] <- xoutSMPL$par[1]
  param_tableSMPL[r,2] <- xoutSMPL$par[2]
}

#look at table
summary(param_tableSMPL)
#average data in table for plotting
simMean  <- mean(param_tableSMPL[,1])
simWidth <- mean(param_tableSMPL[,2])
simDataSMPL <- rnorm(n,simMean,simWidth)

#plot data and estimate
plt1 <- hist(lat,breaks = 40, plot = FALSE)
plt2 <- hist(simDataSMPL, breaks = 80, plot= FALSE)
plot(plt1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plt2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)

hist(lat,freq=FALSE, breaks = 40 ,xlim=c(0,200),ylim=c(0,0.1))
curve(dnorm(x,simMean,simWidth),0,200,add=TRUE)

```

This does not reflect the error surface plotted above - the distribution is broad with no clear maximum, maybe the estimate is driven by the input parameters more than by the data

```{r}
# compare to an estimation with simulated annealing (more robust for local minimae)

# lower number of replication, because sann runs for a longer time
reps <- 5
param_tableSA <- matrix(0,reps,2) 

param_means  <- seq(0,250,10)
param_width  <- seq(0,100,10)

for(r in 1:reps){
  startParams <- pick_params(param_means,param_width)
  # run the estimation with simulated annealing
  xoutSA   <- optim(startParams,rmsd,data1=lat,method = "SANN")
  param_tableSA[r,1] <- xoutSA$par[1]
  param_tableSA[r,2] <- xoutSA$par[2]
}

#summarize results
summary(param_tableSA)
simMeanSA <- mean(param_tableSA[,1])
simWidthSA <- mean(param_tableSA[,2])


simDataSA <- rnorm(n,simMeanSA,simWidthSA)

#and plot them

p1 <- hist(lat,breaks = 20, plot = FALSE)
p2 <- hist(simDataSA, breaks = 40, plot= FALSE)
plot(p1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(p2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)

```
```{r}
# Next, we will try to fit a bimodal distribution. This increases the parameter space. 
# b0 -> mean normal saccades
# b1 -> mean express saccades
# b2 -> width

n <- length(lat)

getregpred2 <- function(params,data1){
  n = length(data1)
  getregpred2 <- c(rnorm(1500,params["b0"],params["b2"]),rnorm(500,params["b1"],params["b2"]))
  
  return(getregpred2)
}

rmsd2 <- function(params,data1){
  # generate predictions
  preds <- getregpred2(params,data1)
  #evaluate the deviation, this computes the sum of squared deviations between data points and devides by the total number of data points to get the mean summed square deviation
  sorted_preds <- sort(preds)
  sorted_data  <- sort(data1)
  
  rmsd2 <- sqrt(sum((sorted_preds-sorted_data)^2)/length(sorted_preds))
}

pick_params2 <- function(param1, param2, param3){
  b0  <- sample(param1,1)
  b1  <- sample(param2,1)
  b2  <- sample(param3,1)
  
  startParams <- c(b0,b1,b2)
  names(startParams) <- c("b0","b1","b2")
  
  return(startParams)
  
}

```

```{r}
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3) 

params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,20,1)

for(r in 1:reps){
  startParams <- pick_params2(params_mean1,params_mean2,params_width)
  
  xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = c(1,1,1),upper = c(200,150,50))
  param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
  param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
  param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}

summary(param_tableSMPLX_bm)
simMean_bm  <- mean(param_tableSMPLX_bm[,1])
simMeanEX_bm  <- mean(param_tableSMPLX_bm[,2])
simWidth_bm <- mean(param_tableSMPLX_bm[,3])
simDataSMPLX_bm <- c(rnorm(1500,simMean_bm,simWidth_bm),rnorm(500,simMeanEX_bm,simWidth_bm))


plot1 <- hist(lat,breaks = 20, plot = FALSE)
plot2 <- hist(simDataSMPLX_bm, breaks = 20, plot= FALSE)
plot(plot1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plot2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)

hist(lat,freq=FALSE, breaks = 40 ,xlim=c(0,200),ylim=c(0,0.1))
curve(dnorm(x,simMean_bm,simWidth_bm),0,200,add=TRUE)
curve(dnorm(x,simMeanEX_bm,simWidth_bm),0,200,add=TRUE)

```

Questions:

The fitting doesn't seem to work well here. What could be the reason?

Is there a way to estimate the proportion of express saccades and normal saccades?




# Next Chapter - Maximum Likelihood


```{r}

```

