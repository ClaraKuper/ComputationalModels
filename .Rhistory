#estimate parameters
xoutSMPL   <- optim(startParams,rmsd,data1=lat,method = "L-BFGS-B", lower = rep(0, length(startParams)))
#write to table
param_tableSMPL[r,1] <- xoutSMPL$par[1]
param_tableSMPL[r,2] <- xoutSMPL$par[2]
}
#look at table
summary(param_tableSMPL)
#average data in table for plotting
simMean  <- mean(param_tableSMPL[,1])
simWidth <- mean(param_tableSMPL[,2])
simDataSMPL <- rnorm(n,simMean,simWidth)
#plot data and estimate
plt1 <- hist(lat,breaks = 40, plot = FALSE)
plt2 <- hist(simDataSMPL, breaks = 80, plot= FALSE)
plot(plt1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plt2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
# compare to an estimation with simulated annealing (more robust for local minimae)
# lower number of replication, because sann runs for a longer time
reps <- 5
param_tableSA <- matrix(0,reps,2)
param_means  <- seq(0,250,10)
param_width  <- seq(0,100,10)
for(r in 1:reps){
startParams <- pick_params(param_means,param_width)
# run the estimation with simulated annealing
xoutSA   <- optim(startParams,rmsd,data1=lat,method = "SANN")
param_tableSA[r,1] <- xoutSA$par[1]
param_tableSA[r,2] <- xoutSA$par[2]
}
#summarize results
summary(param_tableSA)
simMeanSA <- mean(param_tableSA[,1])
simWidthSA <- mean(param_tableSA[,2])
simDataSA <- rnorm(n,simMeanSA,simWidthSA)
#and plot them
p1 <- hist(lat,breaks = 20, plot = FALSE)
p2 <- hist(simDataSA, breaks = 40, plot= FALSE)
plot(p1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(p2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
# compare to an estimation with simulated annealing (more robust for local minimae)
# lower number of replication, because sann runs for a longer time
reps <- 5
param_tableSA <- matrix(0,reps,2)
param_means  <- seq(0,250,10)
param_width  <- seq(0,100,10)
for(r in 1:reps){
startParams <- pick_params(param_means,param_width)
# run the estimation with simulated annealing
xoutSA   <- optim(startParams,rmsd,data1=lat,method = "SANN",lower = rep(0, length(startParams)))
param_tableSA[r,1] <- xoutSA$par[1]
param_tableSA[r,2] <- xoutSA$par[2]
}
#summarize results
summary(param_tableSA)
simMeanSA <- mean(param_tableSA[,1])
simWidthSA <- mean(param_tableSA[,2])
simDataSA <- rnorm(n,simMeanSA,simWidthSA)
#and plot them
p1 <- hist(lat,breaks = 20, plot = FALSE)
p2 <- hist(simDataSA, breaks = 40, plot= FALSE)
plot(p1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(p2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
# Next, we will try to fit a bimodal distribution. This increases the parameter space.
# b0 -> mean normal saccades
# b1 -> mean express saccades
# b2 -> width
startParams <- c(200,50,20)
names(startParams) <- c("b0","b1","b2")
n <- length(lat)
getregpred2 <- function(params,data1){
n = length(data1)
getregpred2 <- c(rnorm(1500,params["b0"],params["b2"]),rnorm(500,params["b1"],params["b2"]))
return(getregpred2)
}
rmsd2 <- function(params,data1){
# generate predictions
preds <- getregpred2(params,data1)
#evaluate the deviation, this computes the sum of squared deviations between data points and devides by the total number of data points to get the mean summed square deviation
rmsd2 <- sqrt(sum((preds-data1)^2)/length(preds))
}
pick_params2 <- function(param1, param2, param3){
b0  <- sample(param1,1)
b1  <- sample(param2,1)
b2  <- sample(param3,1)
startParams <- c(b0,b1,b2)
names(startParams) <- c("b0","b1","b2")
return(startParams)
}
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,100,10)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = rep(0, length(startParams)))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
summary(param_tableSMPLX_bm)
simMean_bm  <- mean(param_tableSMPLX_bm[,1])
simMeanEX_bm  <- mean(param_tableSMPLX_bm[,2])
simWidth_bm <- mean(param_tableSMPLX_bm[,3])
simDataSMPLX_bm <- c(rnorm(1500,simMean_bm,simWidth_bm),rnorm(500,simMeanEX_bm,simWidth_bm))
plot1 <- hist(lat,breaks = 20, plot = FALSE)
plot2 <- hist(simDataSMPLX_bm, breaks = 80, plot= FALSE)
plot(plot1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plot2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
# Next, we will try to fit a bimodal distribution. This increases the parameter space.
# b0 -> mean normal saccades
# b1 -> mean express saccades
# b2 -> width
startParams <- c(200,50,20)
names(startParams) <- c("b0","b1","b2")
n <- length(lat)
getregpred2 <- function(params,data1){
n = length(data1)
getregpred2 <- c(rnorm(1500,params["b0"],params["b2"]),rnorm(500,params["b1"],params["b2"]))
return(getregpred2)
}
rmsd2 <- function(params,data1){
# generate predictions
preds <- getregpred2(params,data1)
#evaluate the deviation, this computes the sum of squared deviations between data points and devides by the total number of data points to get the mean summed square deviation
sorted_preds <- sort(preds)
sorted_data  <- sort(data)
rmsd2 <- sqrt(sum((sorted_preds-sorted_data)^2)/length(sorted_preds))
}
pick_params2 <- function(param1, param2, param3){
b0  <- sample(param1,1)
b1  <- sample(param2,1)
b2  <- sample(param3,1)
startParams <- c(b0,b1,b2)
names(startParams) <- c("b0","b1","b2")
return(startParams)
}
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,100,10)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = rep(0, length(startParams)))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
# Next, we will try to fit a bimodal distribution. This increases the parameter space.
# b0 -> mean normal saccades
# b1 -> mean express saccades
# b2 -> width
startParams <- c(200,50,20)
names(startParams) <- c("b0","b1","b2")
n <- length(lat)
getregpred2 <- function(params,data1){
n = length(data1)
getregpred2 <- c(rnorm(1500,params["b0"],params["b2"]),rnorm(500,params["b1"],params["b2"]))
return(getregpred2)
}
rmsd2 <- function(params,data1){
# generate predictions
preds <- getregpred2(params,data1)
#evaluate the deviation, this computes the sum of squared deviations between data points and devides by the total number of data points to get the mean summed square deviation
sorted_preds <- sort(preds)
sorted_data  <- sort(data1)
rmsd2 <- sqrt(sum((sorted_preds-sorted_data)^2)/length(sorted_preds))
}
pick_params2 <- function(param1, param2, param3){
b0  <- sample(param1,1)
b1  <- sample(param2,1)
b2  <- sample(param3,1)
startParams <- c(b0,b1,b2)
names(startParams) <- c("b0","b1","b2")
return(startParams)
}
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,100,10)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = rep(0, length(startParams)))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
length(startParams)
pick_params2(params_mean1,params_mean2,params_width)
pick_params2(params_mean1,params_mean2,params_width)
pick_params2(params_mean1,params_mean2,params_width)
pick_params2(params_mean1,params_mean2,params_width)
pick_params2(params_mean1,params_mean2,params_width)
pick_params2(params_mean1,params_mean2,params_width)
pick_params2(params_mean1,params_mean2,params_width)
pick_params2(params_mean1,params_mean2,params_width)
pick_params2(params_mean1,params_mean2,params_width)
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,100,10)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = rep(0,length(startParams)))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
summary(param_tableSMPLX_bm)
simMean_bm  <- mean(param_tableSMPLX_bm[,1])
simMeanEX_bm  <- mean(param_tableSMPLX_bm[,2])
simWidth_bm <- mean(param_tableSMPLX_bm[,3])
simDataSMPLX_bm <- c(rnorm(1500,simMean_bm,simWidth_bm),rnorm(500,simMeanEX_bm,simWidth_bm))
plot1 <- hist(lat,breaks = 20, plot = FALSE)
plot2 <- hist(simDataSMPLX_bm, breaks = 80, plot= FALSE)
plot(plot1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plot2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
simMean_bm
simMeanEX_bm
simWidth_bm
simWidth_bm <- 5
simDataSMPLX_bm <- c(rnorm(1500,simMean_bm,simWidth_bm),rnorm(500,simMeanEX_bm,simWidth_bm))
plot1 <- hist(lat,breaks = 20, plot = FALSE)
plot2 <- hist(simDataSMPLX_bm, breaks = 80, plot= FALSE)
plot(plot1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plot2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,100,10)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = rep(0,length(startParams)))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,20,1)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = rep(0,length(startParams)))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
summary(param_tableSMPLX_bm)
simMean_bm  <- mean(param_tableSMPLX_bm[,1])
simMeanEX_bm  <- mean(param_tableSMPLX_bm[,2])
simWidth_bm <- mean(param_tableSMPLX_bm[,3])
simDataSMPLX_bm <- c(rnorm(1500,simMean_bm,simWidth_bm),rnorm(500,simMeanEX_bm,simWidth_bm))
plot1 <- hist(lat,breaks = 20, plot = FALSE)
plot2 <- hist(simDataSMPLX_bm, breaks = 20, plot= FALSE)
plot(plot1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plot2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
# Start the optimalization process with boundaries (L-BFGS-B):
# boundaries are used because the mean latency and the width cannot go negative
# the estimation is repeated "reps" times for a more robust measure (start parameters are fixed)
reps <- 1000
param_tableSMPL <- matrix(0,reps,2)
# define a range of start parameters, the function randomly picks one combination before each estimation
param_means  <- seq(0,250,10)
param_width  <- seq(0,100,10)
for(r in 1:reps){
#choose start parameters
startParams <- pick_params(param_means,param_width)
#estimate parameters
xoutSMPL   <- optim(startParams,rmsd,data1=lat,method = "L-BFGS-B", lower = rep(0, length(startParams)))
#write to table
param_tableSMPL[r,1] <- xoutSMPL$par[1]
param_tableSMPL[r,2] <- xoutSMPL$par[2]
}
# Start the optimalization process with boundaries (L-BFGS-B):
# boundaries are used because the mean latency and the width cannot go negative
# the estimation is repeated "reps" times for a more robust measure (start parameters are fixed)
reps <- 1000
param_tableSMPL <- matrix(0,reps,2)
# define a range of start parameters, the function randomly picks one combination before each estimation
param_means  <- seq(0,250,10)
param_width  <- seq(0,100,10)
for(r in 1:reps){
#choose start parameters
startParams <- pick_params(param_means,param_width)
#estimate parameters
xoutSMPL   <- optim(startParams,rmsd,data1=lat,method = "L-BFGS-B", lower = rep(0, length(startParams)))
#write to table
param_tableSMPL[r,1] <- xoutSMPL$par[1]
param_tableSMPL[r,2] <- xoutSMPL$par[2]
}
#look at table
summary(param_tableSMPL)
#average data in table for plotting
simMean  <- mean(param_tableSMPL[,1])
simWidth <- mean(param_tableSMPL[,2])
simDataSMPL <- rnorm(n,simMean,simWidth)
#plot data and estimate
plt1 <- hist(lat,breaks = 40, plot = FALSE)
plt2 <- hist(simDataSMPL, breaks = 80, plot= FALSE)
plot(plt1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plt2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
hist(lat,freq=FALSE,xlim=c(0,400),ylim=c(0,0.1))
curve(dnorm(n,simMean,simWidth),0,400,add=TRUE)
hist(lat,freq=FALSE,xlim=c(0,300),ylim=c(0,0.1))
curve(dnorm(n,simMean,simWidth),xlim= c(0,400),add=TRUE)
hist(lat,freq=FALSE,xlim=c(0,300),ylim=c(0,0.1))
curve(dnorm(x,simMean,simWidth),0,400,add=TRUE)
hist(lat,freq=FALSE,xlim=c(0,200),ylim=c(0,0.1))
curve(dnorm(x,simMean,simWidth),0,200,add=TRUE)
# Start the optimalization process with boundaries (L-BFGS-B):
# boundaries are used because the mean latency and the width cannot go negative
# the estimation is repeated "reps" times for a more robust measure (start parameters are fixed)
reps <- 1000
param_tableSMPL <- matrix(0,reps,2)
# define a range of start parameters, the function randomly picks one combination before each estimation
param_means  <- seq(0,250,10)
param_width  <- seq(0,100,10)
for(r in 1:reps){
#choose start parameters
startParams <- pick_params(param_means,param_width)
#estimate parameters
xoutSMPL   <- optim(startParams,rmsd,data1=lat,method = "L-BFGS-B", lower = rep(0, length(startParams)))
#write to table
param_tableSMPL[r,1] <- xoutSMPL$par[1]
param_tableSMPL[r,2] <- xoutSMPL$par[2]
}
# Start the optimalization process with boundaries (L-BFGS-B):
# boundaries are used because the mean latency and the width cannot go negative
# the estimation is repeated "reps" times for a more robust measure (start parameters are fixed)
reps <- 1000
param_tableSMPL <- matrix(0,reps,2)
# define a range of start parameters, the function randomly picks one combination before each estimation
param_means  <- seq(0,250,10)
param_width  <- seq(0,100,10)
for(r in 1:reps){
#choose start parameters
startParams <- pick_params(param_means,param_width)
#estimate parameters
xoutSMPL   <- optim(startParams,rmsd,data1=lat,method = "L-BFGS-B", lower = rep(0, length(startParams)), upper = rep(300,200))
#write to table
param_tableSMPL[r,1] <- xoutSMPL$par[1]
param_tableSMPL[r,2] <- xoutSMPL$par[2]
}
#look at table
summary(param_tableSMPL)
#average data in table for plotting
simMean  <- mean(param_tableSMPL[,1])
simWidth <- mean(param_tableSMPL[,2])
simDataSMPL <- rnorm(n,simMean,simWidth)
#plot data and estimate
plt1 <- hist(lat,breaks = 40, plot = FALSE)
plt2 <- hist(simDataSMPL, breaks = 80, plot= FALSE)
plot(plt1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plt2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
hist(lat,freq=FALSE, breaks = 80 ,xlim=c(0,200),ylim=c(0,0.1))
curve(dnorm(x,simMean,simWidth),0,200,add=TRUE)
hist(lat,freq=FALSE, breaks = 40 ,xlim=c(0,200),ylim=c(0,0.1))
curve(dnorm(x,simMean,simWidth),0,200,add=TRUE)
hist(lat,freq=FALSE, breaks = 40 ,xlim=c(0,200),ylim=c(0,0.1))
curve(dnorm(x,simMean_bm,simWidth_bm),0,200,add=TRUE)
curve(dnorm(x,simMeanEX_bm,simWidth_bm),0,200,add=TRUE)
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,20,1)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = rep(0,length(startParams)),upper = c(200,150,50))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
library(ggplot2)
# Generate the data (the data could be saccades and express saccades, for example)
lat_sac <- 150  # mean latency for a saccade
lat_exp <- 80  # mean latency for an express saccade
width   <- 5   # width of the gaussian
# generate data with 1500 data points for normal saccades and 500 data points for express saccades
lat<-c(rnorm(1500,lat_sac,width),rnorm(500,lat_exp,width))
hist(lat, breaks = 40)
# Next, we will try to fit a bimodal distribution. This increases the parameter space.
# b0 -> mean normal saccades
# b1 -> mean express saccades
# b2 -> width
n <- length(lat)
getregpred2 <- function(params,data1){
n = length(data1)
getregpred2 <- c(rnorm(1500,params["b0"],params["b2"]),rnorm(500,params["b1"],params["b2"]))
return(getregpred2)
}
rmsd2 <- function(params,data1){
# generate predictions
preds <- getregpred2(params,data1)
#evaluate the deviation, this computes the sum of squared deviations between data points and devides by the total number of data points to get the mean summed square deviation
sorted_preds <- sort(preds)
sorted_data  <- sort(data1)
rmsd2 <- sqrt(sum((sorted_preds-sorted_data)^2)/length(sorted_preds))
}
pick_params2 <- function(param1, param2, param3){
b0  <- sample(param1,1)
b1  <- sample(param2,1)
b2  <- sample(param3,1)
startParams <- c(b0,b1,b2)
names(startParams) <- c("b0","b1","b2")
return(startParams)
}
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,20,1)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = rep(0,length(startParams)),upper = c(200,150,50))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,20,1)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = c(0,0,0),upper = c(200,150,50))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
# Start the optimalization process with boundaries on L-BFGS-B:
reps <- 1000
param_tableSMPLX_bm <- matrix(0,reps,3)
params_mean1 <- seq(50,200,10)
params_mean2 <- seq(0,150,10)
params_width <- seq(0,20,1)
for(r in 1:reps){
startParams <- pick_params2(params_mean1,params_mean2,params_width)
xoutSMPLX_bm   <- optim(startParams,rmsd2,data1=lat,method = "L-BFGS-B", lower = c(1,1,1),upper = c(200,150,50))
param_tableSMPLX_bm[r,1] <- xoutSMPLX_bm$par[1]
param_tableSMPLX_bm[r,2] <- xoutSMPLX_bm$par[2]
param_tableSMPLX_bm[r,3] <- xoutSMPLX_bm$par[3]
}
summary(param_tableSMPLX_bm)
simMean_bm  <- mean(param_tableSMPLX_bm[,1])
simMeanEX_bm  <- mean(param_tableSMPLX_bm[,2])
simWidth_bm <- mean(param_tableSMPLX_bm[,3])
simDataSMPLX_bm <- c(rnorm(1500,simMean_bm,simWidth_bm),rnorm(500,simMeanEX_bm,simWidth_bm))
plot1 <- hist(lat,breaks = 20, plot = FALSE)
plot2 <- hist(simDataSMPLX_bm, breaks = 20, plot= FALSE)
plot(plot1,col=rgb(0,0,1,1/4), xlim=c(0,200))
plot(plot2,col=rgb(1,0,0,1/4), xlim=c(0,200), add=TRUE)
hist(lat,freq=FALSE, breaks = 40 ,xlim=c(0,200),ylim=c(0,0.1))
curve(dnorm(x,simMean_bm,simWidth_bm),0,200,add=TRUE)
curve(dnorm(x,simMeanEX_bm,simWidth_bm),0,200,add=TRUE)
setwd("C:/Users/Clara Q/Documents/Projects/covid19-tweets/")
setwd("C:/Users/Clara Q/Documents/Projects/covid19-tweets/")
tweet_data <- read.csv('corona_4nodes.csv', sep = ",", header = TRUE, encoding = 'utf-8')
# kick out empty columns
cleanNA_tweets <- tweet_data[,colSums(is.na(tweet_data))<nrow(tweet_data)]
# only consider tweets with location
geoLoc_tweets  <- cleanNA_tweets[which(cleanNA_tweets$user.location!=""),]
# load the emotional valence information
valence <- read.csv("NCR_valence_lexicon.csv", sep =",", header = TRUE, encoding = "utf-8")
View(tweet_data)
View(tweet_data)
View(cleanNA_tweets)
View(cleanNA_tweets)
View(valence)
View(valence)
tweet_valence <- geoLoc_tweets
tweet_valence$valence <- NA
for (t in 1:nrow(tweet_valence)){
tweet <- as.character(tweet_valence$text[t])
split_tweet <- strsplit(tweet, " ")
words       <- split_tweet[[1]]
valence_sum  <- 0
valence_mean <- 0
valence_word <- 0
for (w in words){
if(is.element(tolower(w),tolower(valence$German.de))){
idx         <- which(tolower(valence$German.de) == tolower(w))
valence_sum <- valence_sum + valence$Valence[idx]
valence_word<- valence_word +1
}
}
valence_mean <- valence_sum/valence_word
tweet_valence$valence_mean[t] <- valence_mean
tweet_valence$valence_sum[t] <- valence_sum
}
View(tweet_valence)
View(tweet_valence)
tweet_valence$valence_mean
sorted<-sort(tweet_valence$text,by = tweet_valence$valence_mean)
sorted
